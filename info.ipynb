{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077b92e0-2f69-40ab-b49f-12bc9a37e646",
   "metadata": {},
   "source": [
    "# .hocr files to .csv files\n",
    "\n",
    "This notebook tries to explain how `sol.py` works, so it contains code snippets to let t you play with changes or only explore the solucition before to run it. It is a usefully style of documentation file that let's create some short code experiments and it is nice for presentations too.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91ce06-b1ea-43db-91b8-531b7d1afceb",
   "metadata": {},
   "source": [
    "## First idea ðŸ’¡\n",
    "\n",
    "The first idea is to make imports of some well known python libraries\n",
    "\n",
    "- re for regular expretions\n",
    "- pandas works with data and get the .csv\n",
    "- bs4 for web scrapping (.horc is like html)\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a16d37-dd52-4680-9971-d07dfb3f31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac63bea-7570-4d94-950e-a604683de2ce",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: Parse .hocr file\n",
    "\n",
    "First we write a function to parse the file, we work with **beautifulSoup4**, this python library solve the problem.\n",
    "We need to open the file, then we apply `with` but, we are **just reading**, furthermore we set the second param to `r`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b058a3-467c-499d-ad67-6c2bf3f6b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hocr(path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return BeautifulSoup(file, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ee80-9077-409e-b670-db38247b0bec",
   "metadata": {},
   "source": [
    "## Finding Text Positions\n",
    "\n",
    "Function to figure out the text position: Working with regular expretions we can looking for information in the last funtion output, i.e., the soup param. \n",
    "\n",
    "- `.hocr`files contains coordinates for the text in the file, so, we save data as list of dictionaries\n",
    "- `findall`method let us to get all the `horc`tags with `class='ocrx_word'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "832c3e36-d6a4-44b1-910f-facd15aa5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_positions(soup):\n",
    "    data = []\n",
    "    for span in soup.find_all(class_=['ocrx_word']):\n",
    "        title = span.get('title', '')\n",
    "        coords = re.findall(r'bbox (\\d+) (\\d+) (\\d+) (\\d+)', title)\n",
    "        if coords:\n",
    "            x1, y1, x2, y2 = map(int, coords[0])\n",
    "            text = span.get_text().strip()\n",
    "            if text:\n",
    "                data.append({'text': text, 'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425574d-02d9-4fa2-9614-f424e33d80fd",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `order_data(data)`\n",
    "\n",
    "Sorts a list of dictionaries by the keys `'y1'` and `'x1'` in ascending order.\n",
    "\n",
    "#### **Description**\n",
    "This function takes a list of dictionaries (for example, representing coordinates or positioned elements)\n",
    "and returns it sorted. The data is first sorted by `'y1'`, and in case of ties, by `'x1'`.\n",
    "\n",
    "Itâ€™s useful when working with spatial data, text layout coordinates, \n",
    "or any two-dimensional structure where ordering matters.\n",
    "\n",
    "#### **Parameters**\n",
    "| Name | Type | Description |\n",
    "|------|------|-------------|\n",
    "| `data` | `list[dict]` | A list of dictionaries containing at least the keys `'y1'` and `'x1'`. |\n",
    "\n",
    "#### **Returns**\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| `list[dict]` | A new list sorted according to `'y1'` and `'x1'`. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e16971a-a477-486f-a645-db26291d0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_data(data):\n",
    "    return sorted(data, key=lambda item: (item['y1'], item['x1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56baa3ad-96e4-413b-87ab-52b4c145c03d",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `group_into_rows(data, y_tolerance=10)`\n",
    "\n",
    "This function helps you organize your extracted data into rows based on their vertical positions.  \n",
    "It looks at each elementâ€™s `y1` coordinate and groups together items that are close to each other,  \n",
    "according to a given `y_tolerance` value.\n",
    "\n",
    "So, if two elements have similar `y1` values (within the tolerance range),  \n",
    "theyâ€™ll be placed in the same row â€” just like how text lines appear on a page.\n",
    "\n",
    "#### **Parameters**\n",
    "- `data` (`list[dict]`): The list of items (each one containing a `y1` key).\n",
    "- `y_tolerance` (`int`, default `10`): The maximum allowed vertical difference for items to belong to the same row.\n",
    "\n",
    "#### **Returns**\n",
    "- `list[list[dict]]`: A list of rows, where each row is a list of items grouped by their `y1` proximity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145dc764-b70a-455e-a908-9b2b573491bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_into_rows(data, y_tolerance=10):\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    last_y = None\n",
    "\n",
    "    for item in data:\n",
    "        if last_y is None or abs(item['y1'] - last_y) <= y_tolerance:\n",
    "            current_row.append(item)\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [item]\n",
    "        last_y = item['y1']\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ea85b-356d-42c1-830c-e3bda4708426",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `detect_columns(rows, x_tolerance=30)`\n",
    "\n",
    "This function helps you find the most common column positions in a set of rows.  \n",
    "It looks at the `x1` positions of all items in all rows and groups together values that are close to each other,  \n",
    "based on the `x_tolerance` you set.  \n",
    "\n",
    "The result is a list of integer positions representing the main columns,  \n",
    "so you can later align or process your data by these detected columns.\n",
    "\n",
    "#### **Parameters**\n",
    "- `rows` (`list[list[dict]]`): A list of rows, where each row is a list of items containing at least the key `'x1'`.  \n",
    "- `x_tolerance` (`int`, default `30`): Maximum horizontal difference to consider values part of the same column group.\n",
    "\n",
    "#### **Returns**\n",
    "- `list[int]`: A list of integer positions representing the main columns detected from the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efba374-3f6e-4de0-86f9-14e69109e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_columns(rows, x_tolerance=30):\n",
    "    \"\"\"Encuentra las posiciones de columna mÃ¡s comunes.\"\"\"\n",
    "    x_positions = []\n",
    "    for row in rows:\n",
    "        for cell in row:\n",
    "            x_positions.append(cell['x1'])\n",
    "    x_positions = sorted(x_positions)\n",
    "    \n",
    "    # Agrupamos valores cercanos en rangos\n",
    "    columns = []\n",
    "    current_group = [x_positions[0]]\n",
    "    for x in x_positions[1:]:\n",
    "        if abs(x - np.mean(current_group)) <= x_tolerance:\n",
    "            current_group.append(x)\n",
    "        else:\n",
    "            columns.append(int(np.mean(current_group)))\n",
    "            current_group = [x]\n",
    "    columns.append(int(np.mean(current_group)))\n",
    "    return columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac9f97-98f7-44e2-8acf-f37e14c47198",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `clean_and_normalize_table(table)`\n",
    "\n",
    "This function helps you clean and standardize a table represented as a list of rows.  \n",
    "It removes empty or almost-empty rows, and then makes sure all rows have the same number of columns by filling missing cells with empty strings.  \n",
    "\n",
    "This is useful to prepare your data for further processing or CSV export,  \n",
    "so that all rows have a consistent structure.\n",
    "\n",
    "#### **Parameters**\n",
    "- `table` (`list[list[str]]`): A list of rows, where each row is a list of cell values (strings).\n",
    "\n",
    "#### **Returns**\n",
    "- `list[list[str]]`: A cleaned and normalized table where all rows have the same number of columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbacf5d2-16e5-4418-a86b-5badc00c1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_normalize_table(table):\n",
    "    # Elimina filas vacÃ­as o casi vacÃ­as\n",
    "    cleaned = [row for row in table if sum(1 for cell in row if cell.strip()) > 1]\n",
    "    # Encuentra el mÃ¡ximo nÃºmero de columnas\n",
    "    max_cols = max(len(row) for row in cleaned)\n",
    "    # Normaliza el nÃºmero de columnas\n",
    "    normalized = [row + [''] * (max_cols - len(row)) for row in cleaned]\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792198e5-99a4-42f4-abf9-09723ce3c4bb",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `build_csv(rows, output_path='output.csv', x_tolerance=30)`\n",
    "\n",
    "This function takes processed rows of data and generates a CSV file.  \n",
    "It first detects the main column positions using `detect_columns`, then organizes each row into these columns.  \n",
    "If multiple items fall into the same column, their text is combined with a space.  \n",
    "\n",
    "After constructing the table, it cleans and normalizes it so all rows have the same number of columns,  \n",
    "and finally saves it as a CSV file at the specified output path.  \n",
    "\n",
    "#### **Parameters**\n",
    "- `rows` (`list[list[dict]]`): A list of rows, where each row is a list of items containing at least `'x1'` and `'text'`.  \n",
    "- `output_path` (`str`, default `'output.csv'`): The path where the generated CSV file will be saved.  \n",
    "- `x_tolerance` (`int`, default `30`): Maximum horizontal difference to consider values part of the same column group.\n",
    "\n",
    "#### **Returns**\n",
    "- `None`: The function writes the CSV to disk and prints a confirmation message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92c7357-3687-419e-8897-95e352ca27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_csv(rows, output_path='output.csv', x_tolerance=30):\n",
    "    columns = detect_columns(rows, x_tolerance)\n",
    "    table = []\n",
    "\n",
    "    for row in rows:\n",
    "        line = [''] * len(columns)\n",
    "        for cell in row:\n",
    "            x = cell['x1']\n",
    "            idx = min(range(len(columns)), key=lambda i: abs(columns[i] - x))\n",
    "            if line[idx]:\n",
    "                line[idx] += ' ' + cell['text']\n",
    "            else:\n",
    "                line[idx] = cell['text']\n",
    "        table.append(line)\n",
    "\n",
    "    # Limpieza y normalizaciÃ³n\n",
    "    table = clean_and_normalize_table(table)\n",
    "\n",
    "    df = pd.DataFrame(table)\n",
    "    df.to_csv(output_path, index=False, header=False)\n",
    "    print(f\"CSV generado: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2785ed-ed1d-46ac-85e1-535ed5a5bd20",
   "metadata": {},
   "source": [
    "## ðŸ§© Function: `hocr_to_csv(input_path, output_path='output.csv')`\n",
    "\n",
    "This function is the main pipeline to convert an `.horc` file into a `.csv`.  \n",
    "It parses the `.horc` file, extracts the text with its positions, orders the items, groups them into rows,  \n",
    "and finally builds a cleaned and normalized `.csv` file at the specified location.  \n",
    "\n",
    "#### **Parameters**\n",
    "- `input_path` (`str`): The path to the HOCR file to be processed.  \n",
    "- `output_path` (`str`, default `'output.csv'`): The path where the resulting CSV file will be saved.\n",
    "\n",
    "#### **Returns**\n",
    "- `None`: The function runs the full processing pipeline and writes the CSV to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2504654-b6cf-4bcd-9581-4b5bd6ef257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hocr_to_csv(input_path, output_path='output.csv'):\n",
    "    soup = parse_hocr(input_path)\n",
    "    data = extract_text_positions(soup)\n",
    "    ordered = order_data(data)\n",
    "    rows = group_into_rows(ordered)\n",
    "    build_csv(rows, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d317a1-0aee-40e3-a679-ffba68f586f6",
   "metadata": {},
   "source": [
    "## ðŸ§  Example and Request Process\n",
    "\n",
    "Below, you can experiment with the previously defined Python functions to generate as many `.csv` files as you need.  \n",
    "Start with a `list` of file names and iterate through it by applying the `hocr_to_csv` function.\n",
    "\n",
    "> ðŸ’¡ **Note:** You can change the output directory by modifying the corresponding variable in the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07424e90-c838-4def-bc43-eaf802240627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV generado: files/csv_files/1C_5.csv\n",
      "CSV generado: files/csv_files/1E_1.csv\n",
      "CSV generado: files/csv_files/3T_4.csv\n"
     ]
    }
   ],
   "source": [
    "names = ['1C_5.hocr', '1E_1.hocr', '3T_4.hocr']\n",
    "for name in names:\n",
    "    hocr_input = 'files/hocr_files/' + name\n",
    "    csv_output = 'files/csv_files/' + name[:4] + '.csv'\n",
    "    hocr_to_csv(hocr_input, csv_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
